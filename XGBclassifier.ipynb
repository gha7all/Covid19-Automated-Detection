{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "D9Cg8dV04LyJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import os\n",
    "import seaborn as sns\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from google.colab import drive\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWohFpu_vHe3"
   },
   "source": [
    "## loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hSqy8Bx4Dt2i"
   },
   "outputs": [],
   "source": [
    "SIZE = 256\n",
    "train_images = []\n",
    "train_labels = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rna4sjbevS0t"
   },
   "source": [
    "### importing each image and set the current directory name as its label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eQ33LlY3D7Hf",
    "outputId": "4dbd3cb0-968c-4791-9827-97053e898461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pneumonia\n",
      "No_findings\n",
      "Covid-19\n"
     ]
    }
   ],
   "source": [
    "ext = ['png', 'jpg', 'jpeg'] \n",
    "\n",
    "for directory_path in glob.glob(\"PATH TO YOU LOCAL DATASET\"):\n",
    "    splited = directory_path.split(\"/\") #use \\ if you're on windows \n",
    "    label = splited[-1]\n",
    "    print(label)\n",
    "    for e in ext:\n",
    "      for img_path in glob.glob(os.path.join(directory_path, \"*.\" + e)):\n",
    "          #print(img_path)\n",
    "           img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "           img = cv2.resize(img, (SIZE, SIZE))\n",
    "           train_images.append(img)\n",
    "           train_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hjPnqzQZKorZ"
   },
   "outputs": [],
   "source": [
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "if0mVrFWKwM6"
   },
   "outputs": [],
   "source": [
    "test_images = []\n",
    "test_labels = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sJlRpXf3Kso5",
    "outputId": "ada19727-6203-4b04-8566-65c1d4db1905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pneumonia\n",
      "No_findings\n",
      "Covid-19\n"
     ]
    }
   ],
   "source": [
    "ext = ['png', 'jpg', 'jpeg'] \n",
    "\n",
    "for directory_path in glob.glob(\"PATH TO YOU LOCAL DATASET\"):\n",
    "    splited_test = directory_path.split(\"/\") #use \\ if you're on windows\n",
    "    label_test = splited_test[-1]\n",
    "    print(label_test)\n",
    "    for e in ext:\n",
    "      for img_path in glob.glob(os.path.join(directory_path, \"*.\" + e)):\n",
    "          #print(img_path)\n",
    "          img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "          img = cv2.resize(img, (SIZE, SIZE))\n",
    "          test_images.append(img)\n",
    "          test_labels.append(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aqkmy9EhNAgD"
   },
   "outputs": [],
   "source": [
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8eOrhcUvoOa"
   },
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zXozooIvur4"
   },
   "source": [
    "### label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vbtsRuiGNDg3"
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(test_labels)\n",
    "test_labels_encoded = le.transform(test_labels)\n",
    "le.fit(train_labels)\n",
    "train_labels_encoded = le.transform(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNX0T2NXv2Bm"
   },
   "source": [
    "### spliting the dataset into training set and test set\n",
    "we already split the dataset in our directory, but for the matter of clean coding, we're changing their name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3NV1G-FADtDx"
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJTBFHFhwZBq"
   },
   "source": [
    "### scaling train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wp7lpWbqweB8"
   },
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UFY9dw_whGX"
   },
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGvWYF0gxsYH"
   },
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gG5yuF5MIebj"
   },
   "outputs": [],
   "source": [
    "features = []\n",
    "extracted_feature = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pQrwbY8CNRJ6",
    "outputId": "8a1d94b1-59bc-4e01-fdaa-7179c131be3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 0s 0us/step\n",
      "58900480/58889256 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "VGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3), pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "aLJMOoZ6NYjO"
   },
   "outputs": [],
   "source": [
    "extracted_feature = VGG_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ToRxk7OCywdz",
    "outputId": "44c697d4-2bc3-4ef9-8358-cf986cc9bea9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 512)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VS8qjMHCPPux"
   },
   "outputs": [],
   "source": [
    "features = extracted_feature.reshape(extracted_feature.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ECH9KnTxwPX"
   },
   "source": [
    "### Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lxc4Ip4M25Tc"
   },
   "outputs": [],
   "source": [
    "features = []\n",
    "extracted_feature = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "njHG2ByVxzdZ",
    "outputId": "d85a331d-0d69-418f-a8a0-3ad1d38bc2ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 1s 0us/step\n",
      "87924736/87910968 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "inception_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3), pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "kFVPkABCykjD"
   },
   "outputs": [],
   "source": [
    "extracted_feature =  inception_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S26XuSm13DQs",
    "outputId": "ba7fd0bc-082e-4763-deb5-474bb91b8658"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 2048)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "cMpsmBKUyvB5"
   },
   "outputs": [],
   "source": [
    "features = extracted_feature.reshape(extracted_feature.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbD_w9vxy2_T"
   },
   "source": [
    "## Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "MVzVZpBmy-jJ"
   },
   "outputs": [],
   "source": [
    "features = []\n",
    "extracted_feature = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lAZTIsouzAh2"
   },
   "outputs": [],
   "source": [
    "xception_model = Xception(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BoILJ9bkzDih"
   },
   "outputs": [],
   "source": [
    "extracted_feature =  xception_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uVu9tFwgy5hk"
   },
   "outputs": [],
   "source": [
    "features = extracted_feature.reshape(extracted_feature.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24SL7zT0wrXD"
   },
   "source": [
    "## traning the model\n",
    "### using extracted features to train the xgbclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uu5IJCyFPXvj",
    "outputId": "7c467aca-a9ad-436d-9838-6da3b8f78f0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(objective='multi:softmax')\n",
    "model.fit(features, y_train) #For sklearn no one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7z9mkbkAw8eC"
   },
   "source": [
    "## predict test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "djdhIU4BQ2ch"
   },
   "outputs": [],
   "source": [
    "X_test_feature = xception_model.predict(x_test)\n",
    "X_test_features = X_test_feature.reshape(X_test_feature.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "d9rtC4Mf_rU2"
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test_features)\n",
    "#Inverse le transform to get original label back. \n",
    "prediction = le.inverse_transform(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BZ-GIyFxApv"
   },
   "source": [
    "## accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XXMd1TPqQ_2b",
    "outputId": "87f4684a-d3f8-4e87-9f68-54cd9723d726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy = \", metrics.accuracy_score(test_labels, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8FxtQtHxEYZ"
   },
   "source": [
    "## confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NbzmqyHIROzM"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u34NOq4xRR5e"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shaped-cleaning"
   },
   "outputs": [],
   "source": [
    "n=np.random.randint(0, x_test.shape[0])\n",
    "img = x_test[n]\n",
    "plt.imshow(img)\n",
    "input_img = np.expand_dims(img, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "input_img_feature=VGG_model.predict(input_img)\n",
    "input_img_features=input_img_feature.reshape(input_img_feature.shape[0], -1)\n",
    "prediction = model.predict(input_img_features)[0] \n",
    "prediction = le.inverse_transform([prediction])  #Reverse the label encoder to original name\n",
    "print(\"The prediction for this image is: \", prediction)\n",
    "print(\"The actual label for this image is: \", test_labels[n])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "new-method.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
